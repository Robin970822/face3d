{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c024118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import bz2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "from face3d import mesh\n",
    "from face3d.morphable_model import MorphabelModel\n",
    "from face3d.render_utils.render.render_operator import Render\n",
    "\n",
    "LANDMARKS_MODEL_URL = 'http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2'\n",
    "\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def unpack_bz2(src_path):\n",
    "    data = bz2.BZ2File(src_path).read()\n",
    "    dst_path = src_path[:-4]\n",
    "    with open(dst_path, 'wb') as fp:\n",
    "        fp.write(data)\n",
    "    return dst_path\n",
    "\n",
    "def reverse_to_image(vertices, h, w, is_perspective = False):\n",
    "    projected_vertices = vertices.copy()\n",
    "    # flip vertics along y-axis\n",
    "    projected_vertices[:, 1] = h - projected_vertices[:, 1] - 1\n",
    "    # move to center of image\n",
    "    projected_vertices[:, 0] -= w/2\n",
    "    projected_vertices[:, 1] -= h/2\n",
    "    if is_perspective:\n",
    "        projected_vertices[:, 0] /= w/2\n",
    "        projected_vertices[:, 1] /= h/2\n",
    "    return projected_vertices\n",
    "\n",
    "class LandmarksDetector:\n",
    "    def __init__(self, predictor_model_path):\n",
    "        \"\"\"\n",
    "        :param predictor_model_path: path to shape_predictor_68_face_landmarks.dat file\n",
    "        \"\"\"\n",
    "        self.detector = dlib.get_frontal_face_detector()  # cnn_face_detection_model_v1 also can be used\n",
    "        self.shape_predictor = dlib.shape_predictor(predictor_model_path)\n",
    "\n",
    "    def get_landmarks(self, img):\n",
    "        dets = self.detector(img, 1)\n",
    "        detection = dets[0]\n",
    "        face_landmarks = [(item.x, item.y) for item in self.shape_predictor(img, detection).parts()]\n",
    "        return detection, face_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ca1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = '_zero_expression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28076b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_root = '../examples/Data/train_renamed/'\n",
    "result_root = f'../examples/results/train_renamed{suffix}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bb91362",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_image_path, fitted_image_path, mean_neutral_path = list(map(lambda x: os.path.join(result_root, x), \n",
    "                                                                     ['landmark', 'fitted', 'mean_neutral']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4072b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = list(map(lambda x: ensure_dir(x), [landmark_image_path, fitted_image_path, mean_neutral_path]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8333fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_model_path = unpack_bz2(get_file('shape_predictor_68_face_landmarks.dat.bz2', LANDMARKS_MODEL_URL, cache_subdir='temp'))\n",
    "landmarks_detector = LandmarksDetector(landmarks_model_path)\n",
    "\n",
    "bfm = MorphabelModel('../examples/Data/BFM/Out/BFM.mat')\n",
    "RenderAgent = Render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340f213d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:06<00:00,  3.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for img_name in tqdm(os.listdir(img_root)):\n",
    "    raw_img_path = os.path.join(img_root, img_name)\n",
    "    img = cv2.imread(raw_img_path)\n",
    "    # landmarks detection\n",
    "    detection, face_landmarks = landmarks_detector.get_landmarks(img)\n",
    "\n",
    "    show_img = img.copy()\n",
    "    show_img = cv2.rectangle(show_img, (detection.left(), detection.top()), (detection.right(), detection.bottom()), (0, 255, 0), 2)\n",
    "    for i, landmark in enumerate(face_landmarks):\n",
    "        cv2.circle(show_img, landmark, 2, (0, 255, 0), -1)\n",
    "    cv2.imwrite(os.path.join(landmark_image_path, f'ldmk_{img_name}'), show_img)\n",
    "\n",
    "    h, w, _ = img.shape\n",
    "    x_face_landmarks = np.array(face_landmarks).astype('float64')\n",
    "    projected_vertices = reverse_to_image(x_face_landmarks, h, w)\n",
    "    X_ind = bfm.kpt_ind\n",
    "    # fitting\n",
    "    fitted_sp, fitted_ep, fitted_s, fitted_angles, fitted_t = bfm.fit(projected_vertices, X_ind, max_iter=10, withExpression=False)\n",
    "\n",
    "    # rendering fitted parameters\n",
    "    fitted_vertices = bfm.generate_vertices(fitted_sp, fitted_ep)\n",
    "\n",
    "    transformed_vertices = bfm.transform(fitted_vertices, fitted_s, fitted_angles, fitted_t)\n",
    "    transformed_vertices = bfm.transform(transformed_vertices, 1, [0, 180, 0], [0, 0, 0])\n",
    "    image_vertices = mesh.transform.to_image(transformed_vertices, h, w)\n",
    "    fitted_image = np.flip(RenderAgent(np.flip(img, 1), image_vertices, bfm.triangles), 1).copy()\n",
    "    cv2.imwrite(os.path.join(fitted_image_path, f'fitted{suffix}_{img_name}'), fitted_image)\n",
    "\n",
    "    image_landmarks = image_vertices[bfm.kpt_ind, :2]\n",
    "    for i, landmark in enumerate(image_landmarks):\n",
    "        cv2.circle(fitted_image, tuple((landmark).astype('int')), 2, (0, 0, 255), -1)\n",
    "    for i, landmark in enumerate(face_landmarks):\n",
    "        cv2.circle(fitted_image, landmark, 2, (0, 255, 0), -1)\n",
    "    cv2.imwrite(os.path.join(fitted_image_path, f'fitted_with_ldmk{suffix}_{img_name}'), fitted_image)\n",
    "\n",
    "    fitted_vertices = bfm.generate_vertices(fitted_sp, bfm.get_exp_para('zero'))\n",
    "\n",
    "    transformed_vertices = bfm.transform(fitted_vertices, fitted_s, [0, 180, 0], [0, 0, 0])\n",
    "    image_vertices = mesh.transform.to_image(transformed_vertices, h, w)\n",
    "    image_render = RenderAgent(np.ones_like(img), image_vertices, bfm.triangles)\n",
    "    cv2.imwrite(os.path.join(mean_neutral_path, f'mean_neutral_render{suffix}_{img_name}'), image_render)\n",
    "\n",
    "    transformed_vertices = bfm.transform(fitted_vertices, fitted_s, [0, -90, 0], [w / 4, 0, 0])\n",
    "    image_vertices = mesh.transform.to_image(transformed_vertices, h, w)\n",
    "    image_render = RenderAgent(np.ones_like(img), image_vertices, bfm.triangles)\n",
    "    cv2.imwrite(os.path.join(mean_neutral_path, f'mean_neutral_render{suffix}_left_{img_name}'), image_render)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a414789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
